{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCRmq6ap85CD",
        "outputId": "17cb573f-47b8-4d20-c8b7-9fb6b33a265b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qn /content/drive/MyDrive/open.zip -d /content/"
      ],
      "metadata": {
        "id": "MdZlhjtA87Zy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj7Cq2oP88l2",
        "outputId": "488c67bc-cbc6-4b3e-dcc9-d896b6ff7797"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch-geometric, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch-geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKqe_pm68-BW",
        "outputId": "800717e1-cea2-4566-aa2a-d98346fe315c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting janome\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from janome.tokenizer import Tokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "# 필요한 NLTK 데이터 다운로드\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# 데이터 로드\n",
        "view_log_train = pd.read_csv('view_log.csv')\n",
        "article_info = pd.read_csv('article_info.csv')\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "# 결측치 처리\n",
        "article_info['userCountry'].fillna('Unknown', inplace=True)\n",
        "article_info['userRegion'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# 불용어 로드\n",
        "stop_words_dict = {\n",
        "    'en': stopwords.words('english'),\n",
        "    'pt': stopwords.words('portuguese'),\n",
        "    'la': ['et', 'in', 'de'],\n",
        "    'es': stopwords.words('spanish')\n",
        "}\n",
        "\n",
        "# 일본어 불용어 직접 정의\n",
        "japanese_stop_words = ['これ', 'それ', 'あれ', 'この', 'その', 'あの', 'ここ', 'そこ', 'あそこ', 'こちら', 'どこ', 'だれ', 'なに', 'なん']\n",
        "\n",
        "# 전처리 함수 정의\n",
        "def preprocess_text(text, language):\n",
        "    # URL 제거\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    if language == 'en':\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    elif language == 'pt':\n",
        "        text = re.sub(r'[^a-zA-Z0-9áéíóúâêîôûãõçÇ\\s]', '', text)\n",
        "    elif language == 'la':\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    elif language == 'ja':\n",
        "        text = re.sub(r'[^\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF\\s]', '', text)\n",
        "    elif language == 'es':\n",
        "        text = re.sub(r'[^a-zA-Z0-9áéíóúñÑ\\s]', '', text)\n",
        "\n",
        "    # 소문자 변환\n",
        "    text = text.lower()\n",
        "\n",
        "    # 토큰화 및 불용어 제거\n",
        "    if language == 'ja':\n",
        "        tokenizer = Tokenizer()\n",
        "        tokens = [token.surface for token in tokenizer.tokenize(text)]\n",
        "        tokens = [token for token in tokens if token not in japanese_stop_words]\n",
        "    else:\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        stop_words = stop_words_dict.get(language, [])\n",
        "        tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# 모든 기사에 대해 전처리 적용\n",
        "article_info['ProcessedContent'] = article_info.apply(lambda row: preprocess_text(row['Content'], row['Language']), axis=1)\n",
        "\n",
        "# TF-IDF 벡터화 (차원 축소 추가)\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(article_info['ProcessedContent'])\n",
        "\n",
        "# TruncatedSVD를 사용하여 TF-IDF 벡터의 차원을 축소\n",
        "n_components = 64\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "reduced_tfidf_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "# 유사도 행렬 계산\n",
        "content_similarity = cosine_similarity(reduced_tfidf_matrix)\n",
        "\n",
        "# 사용자-기사 행렬 생성\n",
        "user_article_matrix = view_log_train.groupby(['userID', 'articleID']).size().unstack(fill_value=0)\n",
        "\n",
        "# User-Article Matrix 크기 정의\n",
        "num_users, num_articles = user_article_matrix.shape\n",
        "\n",
        "# 그래프 데이터 준비\n",
        "user_ids = user_article_matrix.index.tolist()\n",
        "article_ids = user_article_matrix.columns.tolist()\n",
        "edge_index = []\n",
        "for user_idx, user_id in enumerate(user_ids):\n",
        "    for article_idx, article_id in enumerate(article_ids):\n",
        "        if user_article_matrix.iloc[user_idx, article_idx] > 0:\n",
        "            edge_index.append([user_idx, len(user_ids) + article_idx])\n",
        "            edge_index.append([len(user_ids) + article_idx, user_idx])\n",
        "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# 노드 특성 준비\n",
        "user_features = torch.randn(num_users, n_components)\n",
        "article_features = torch.tensor(reduced_tfidf_matrix, dtype=torch.float)\n",
        "x = torch.cat([user_features, article_features], dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhnyN_Ph9MrC",
        "outputId": "da500570-49d7-4ab7-cc6c-5e6d505f63ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, num_users, num_articles):\n",
        "        super(HybridGNN, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.user_proj = torch.nn.Linear(hidden_channels, num_articles)\n",
        "        self.article_proj = torch.nn.Linear(hidden_channels, num_users)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        user_emb = self.user_proj(x[:num_users])\n",
        "        article_emb = self.article_proj(x[num_users:])\n",
        "        return user_emb, article_emb.t()\n",
        "\n",
        "# 모델 초기화 및 학습\n",
        "model = HybridGNN(in_channels=x.size(1), hidden_channels=64, num_users=num_users, num_articles=num_articles)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    user_emb, article_emb = model(x, edge_index)\n",
        "    pred = user_emb  # user_emb는 이미 (num_users, num_articles) 크기입니다\n",
        "    target = torch.tensor(user_article_matrix.values, dtype=torch.float)\n",
        "    loss = F.mse_loss(pred, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    user_emb, article_emb = model(x, edge_index)\n",
        "    gnn_similarity = user_emb  # user_emb는 이미 (num_users, num_articles) 크기입니다\n",
        "\n",
        "    # content_similarity의 크기를 확인하고 필요한 경우 조정\n",
        "    if content_similarity.shape != (num_users, num_articles):\n",
        "        print(\"Warning: content_similarity shape mismatch. Adjusting...\")\n",
        "        content_similarity_adj = content_similarity[:num_users, :num_articles]\n",
        "    else:\n",
        "        content_similarity_adj = content_similarity\n",
        "\n",
        "    final_scores = 0.44 * gnn_similarity.numpy() + 0.28 * user_article_matrix.values + 0.28 * content_similarity_adj\n",
        "\n",
        "# 추천 생성\n",
        "recommendations = []\n",
        "for idx, user in enumerate(user_ids):\n",
        "    sorted_indices = final_scores[idx].argsort()[::-1]\n",
        "    top5recommend = [article_ids[i] for i in sorted_indices[:5]]\n",
        "    recommendations.extend([[user, article] for article in top5recommend])\n",
        "\n",
        "# DataFrame 생성 및 제출 파일 저장\n",
        "top_recommendations = pd.DataFrame(recommendations, columns=['userID', 'articleID'])\n",
        "submission['articleID'] = top_recommendations['articleID']\n",
        "submission.to_csv('hybrid_gnn_recommendation_submission.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZx_s8sW9aiB",
        "outputId": "910b089c-d08f-401f-daa0-756a7867fb8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.05307191237807274\n",
            "Epoch 10, Loss: 0.02470482513308525\n",
            "Epoch 20, Loss: 0.024088649079203606\n",
            "Epoch 30, Loss: 0.023858824744820595\n",
            "Epoch 40, Loss: 0.02352830395102501\n",
            "Epoch 50, Loss: 0.02300015278160572\n",
            "Epoch 60, Loss: 0.022325007244944572\n",
            "Epoch 70, Loss: 0.021598927676677704\n",
            "Epoch 80, Loss: 0.02094309590756893\n",
            "Epoch 90, Loss: 0.020459502935409546\n",
            "Epoch 100, Loss: 0.01980516128242016\n",
            "Epoch 110, Loss: 0.019279710948467255\n",
            "Epoch 120, Loss: 0.018789708614349365\n",
            "Epoch 130, Loss: 0.018357520923018456\n",
            "Epoch 140, Loss: 0.01796562410891056\n",
            "Epoch 150, Loss: 0.017597565427422523\n",
            "Epoch 160, Loss: 0.017252517864108086\n",
            "Epoch 170, Loss: 0.01693050004541874\n",
            "Epoch 180, Loss: 0.01662309654057026\n",
            "Epoch 190, Loss: 0.016346637159585953\n",
            "Epoch 200, Loss: 0.01607615500688553\n",
            "Epoch 210, Loss: 0.0158180370926857\n",
            "Epoch 220, Loss: 0.015548937022686005\n",
            "Epoch 230, Loss: 0.015283344313502312\n",
            "Epoch 240, Loss: 0.015030354261398315\n",
            "Epoch 250, Loss: 0.014789517968893051\n",
            "Epoch 260, Loss: 0.01457845326513052\n",
            "Epoch 270, Loss: 0.014379939995706081\n",
            "Epoch 280, Loss: 0.014197439886629581\n",
            "Epoch 290, Loss: 0.014026819728314877\n",
            "Epoch 300, Loss: 0.013863600790500641\n",
            "Epoch 310, Loss: 0.013707933947443962\n",
            "Epoch 320, Loss: 0.013562539592385292\n",
            "Epoch 330, Loss: 0.01342980470508337\n",
            "Epoch 340, Loss: 0.013297360390424728\n",
            "Epoch 350, Loss: 0.013182022608816624\n",
            "Epoch 360, Loss: 0.0130546186119318\n",
            "Epoch 370, Loss: 0.012941977940499783\n",
            "Epoch 380, Loss: 0.012840064242482185\n",
            "Epoch 390, Loss: 0.012742218561470509\n",
            "Epoch 400, Loss: 0.012699591927230358\n",
            "Epoch 410, Loss: 0.012586981058120728\n",
            "Epoch 420, Loss: 0.012502935715019703\n",
            "Epoch 430, Loss: 0.012429454363882542\n",
            "Epoch 440, Loss: 0.01236455887556076\n",
            "Epoch 450, Loss: 0.012320323847234249\n",
            "Epoch 460, Loss: 0.01225990615785122\n",
            "Epoch 470, Loss: 0.012184067629277706\n",
            "Epoch 480, Loss: 0.012129404582083225\n",
            "Epoch 490, Loss: 0.012078172527253628\n",
            "Epoch 500, Loss: 0.012039161287248135\n",
            "Epoch 510, Loss: 0.011981920339167118\n",
            "Epoch 520, Loss: 0.011932511813938618\n",
            "Epoch 530, Loss: 0.011892218142747879\n",
            "Epoch 540, Loss: 0.011857239529490471\n",
            "Epoch 550, Loss: 0.011816781014204025\n",
            "Epoch 560, Loss: 0.011771410703659058\n",
            "Epoch 570, Loss: 0.011736633256077766\n",
            "Epoch 580, Loss: 0.011710608378052711\n",
            "Epoch 590, Loss: 0.011688806116580963\n",
            "Epoch 600, Loss: 0.011652892455458641\n",
            "Epoch 610, Loss: 0.011620162054896355\n",
            "Epoch 620, Loss: 0.011590000241994858\n",
            "Epoch 630, Loss: 0.01156142819672823\n",
            "Epoch 640, Loss: 0.011562112718820572\n",
            "Epoch 650, Loss: 0.011523694731295109\n",
            "Epoch 660, Loss: 0.011496124789118767\n",
            "Epoch 670, Loss: 0.011479085311293602\n",
            "Epoch 680, Loss: 0.0114516606554389\n",
            "Epoch 690, Loss: 0.011452256701886654\n",
            "Epoch 700, Loss: 0.011426739394664764\n",
            "Epoch 710, Loss: 0.01139846071600914\n",
            "Epoch 720, Loss: 0.011398158967494965\n",
            "Epoch 730, Loss: 0.011375483125448227\n",
            "Epoch 740, Loss: 0.011365463025867939\n",
            "Epoch 750, Loss: 0.011344332247972488\n",
            "Epoch 760, Loss: 0.011324012652039528\n",
            "Epoch 770, Loss: 0.011308839544653893\n",
            "Epoch 780, Loss: 0.011306343600153923\n",
            "Epoch 790, Loss: 0.011288134381175041\n",
            "Epoch 800, Loss: 0.011274479329586029\n",
            "Epoch 810, Loss: 0.011258353479206562\n",
            "Epoch 820, Loss: 0.01124676875770092\n",
            "Epoch 830, Loss: 0.011230949312448502\n",
            "Epoch 840, Loss: 0.011289788410067558\n",
            "Epoch 850, Loss: 0.011221627704799175\n",
            "Epoch 860, Loss: 0.011200620792806149\n",
            "Epoch 870, Loss: 0.011185785755515099\n",
            "Epoch 880, Loss: 0.011172197759151459\n",
            "Epoch 890, Loss: 0.011160964146256447\n",
            "Epoch 900, Loss: 0.01115734688937664\n",
            "Epoch 910, Loss: 0.011169317178428173\n",
            "Epoch 920, Loss: 0.011143089272081852\n",
            "Epoch 930, Loss: 0.011123859323561192\n",
            "Epoch 940, Loss: 0.011114933528006077\n",
            "Epoch 950, Loss: 0.011127959005534649\n",
            "Epoch 960, Loss: 0.011110152117908001\n",
            "Epoch 970, Loss: 0.011098953895270824\n",
            "Epoch 980, Loss: 0.011087379418313503\n",
            "Epoch 990, Loss: 0.011079411022365093\n",
            "Warning: content_similarity shape mismatch. Adjusting...\n"
          ]
        }
      ]
    }
  ]
}
